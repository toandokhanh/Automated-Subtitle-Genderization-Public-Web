{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "68eb800c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: male\n",
      "Probabilities: tensor([0.0166, 0.9834])\n"
     ]
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "# Assuming you have a trained model exported from your training code\n",
    "model_path = \"export_step2.pkl\"\n",
    "\n",
    "# Load the exported model\n",
    "learn = load_learner(model_path)\n",
    "\n",
    "# Example: Load an image and make predictions\n",
    "image_path = \"my_mfcs/0_54_3.jpg\"  # Replace with the path to your test image\n",
    "img = PILImage.create(image_path)\n",
    "\n",
    "# Make predictions\n",
    "prediction, _, _ = learn.predict(img)\n",
    "\n",
    "# Print the predicted class and probabilities\n",
    "print(\"Predicted class:\", prediction)\n",
    "print(\"Probabilities:\", _)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabac4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.io.wavfile\n",
    "from skimage.transform import resize\n",
    "import librosa\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Constants\n",
    "kMY_WAVS_DIR = '../AudioMNIST/3666'\n",
    "kMY_MFCS_DIR = '../mfc_dataset_3666'\n",
    "model_path = \"export_step1.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "541c516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wavs_and_evaluate(wav_dir, mfc_dir):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(mfc_dir, exist_ok=True)\n",
    "\n",
    "    for fname in tqdm(os.listdir(wav_dir), desc=\"Processing WAV Files\"):\n",
    "        wav_path = os.path.join(wav_dir, fname)\n",
    "        sample_rate, signal = scipy.io.wavfile.read(wav_path)\n",
    "\n",
    "        # Skip signals that are too short\n",
    "        if len(signal) <= 2:\n",
    "            print(f\"Skipping {fname} due to very short signal\")\n",
    "            continue\n",
    "\n",
    "        # Adjust n_fft based on the length of the input signal\n",
    "        n_fft = min(1200, len(signal) // 2)\n",
    "\n",
    "        # Process the signal\n",
    "        max_samples = int(0.9999583333333333 * sample_rate)\n",
    "        if len(signal) > max_samples:\n",
    "            signal = signal[:max_samples]\n",
    "        else:\n",
    "            signal = np.pad(signal, (0, max_samples - len(signal)), mode='constant')\n",
    "        n_fft = 512  # hoặc 512, tùy thuộc vào kích thước của tín hiệu bạn đang xử lý\n",
    "\n",
    "        mfc = librosa.feature.mfcc(\n",
    "            y=signal.astype(float),\n",
    "            sr=sample_rate,\n",
    "            n_mfcc=12,\n",
    "            dct_type=2,\n",
    "            norm='ortho',\n",
    "            lifter=22,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=int(sample_rate * 0.01),\n",
    "            power=2,\n",
    "            center=False,\n",
    "            window='hamming',\n",
    "            n_mels=40\n",
    "        )\n",
    "\n",
    "\n",
    "        # Rest of your code remains unchanged\n",
    "        mfc_3d = resize(np.rollaxis(np.array([mfc] * 3), 0, 3), (224, 224, 3))\n",
    "        mfc_img = ((mfc_3d - mfc_3d.min()) / (mfc_3d.max() - mfc_3d.min()) * 255).astype('uint8')\n",
    "\n",
    "        mfc_file_name = os.path.splitext(fname)[0] + '.jpg'\n",
    "        mfc_img_path = os.path.join(mfc_dir, mfc_file_name)\n",
    "        Image.fromarray(mfc_img).save(mfc_img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a192d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing WAV Files: 100%|█████████████████████████████████████████████████████████| 2346/2346 [00:46<00:00, 50.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process WAVs and evaluate\n",
    "process_wavs_and_evaluate(kMY_WAVS_DIR, kMY_MFCS_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ac413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ab5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
